{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arkajyotibhattacharya/fundusAI/blob/dev/OcularDiseaseSegmentationCase.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDGGqEcKxdX-"
      },
      "source": [
        "# Ocular Disease Classification\n",
        "*Dataset*: Ocular Disease Recognition (https://www.kaggle.com/datasets/andrewmvd/ocular-disease-recognition-odir5k/data)\n",
        "\n",
        "*Additional Dataset*: Cataract Dataset (https://www.kaggle.com/datasets/jr2ngb/cataractdataset)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Basic collaboration guidelines:\n",
        "\n",
        "The\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "dSsSfUF39en3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "taPA_M87xdYA"
      },
      "source": [
        "# 1. Import Packages, Connect to Kaggle, and Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "Xe9CaV_r3VRy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c40ff0f6-b6fb-4a98-bdd7-6f9ffabb8422"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.61.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.3.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.12.19)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.7.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.0.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.76.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.15.1)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.18.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow) (2026.1.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.5)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "# ONLY FOR GOOGLE COLLAB: Install libraries and clean workspace\n",
        "!pip install pandas numpy matplotlib seaborn tensorflow scikit-learn\n",
        "!rm -rf /content/sample_data\n",
        "\n",
        "# ONLY FOR LOCAL USAGE / VSC: Setup correct kernel\n",
        "# Steps\n",
        "# - 1. click in top right on select kernel and click on \"Python Environments\" -> \"umcg-48-hour-case (Python 3.12.12)\"\n",
        "# - 2. run code below\n",
        "# - if needed: install ipykernel and pip package in popup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pbjDog4wxdYA"
      },
      "outputs": [],
      "source": [
        "# Import dependencies and suppress warnings\n",
        "from warnings import filterwarnings\n",
        "filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "import seaborn as sns\n",
        "import time\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CoRjJqwI9XNx"
      },
      "source": [
        "### Quick guide to setup connection with Kaggle\n",
        "\n",
        "Steps:\n",
        "1. Sign in / register to Kaggle: https://www.kaggle.com/.\n",
        "2. Click on your profile and go to \"Settings\": https://www.kaggle.com/settings.\n",
        "3. Go to \"API Tokens (Recommended)\" and click on \"Generate New Token\".\n",
        "4. Give it a name (e.g. token-umcg-48-hour-case) and create the token.\n",
        "5. Save the API token and paste it below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DO8FjlHT1G1H"
      },
      "outputs": [],
      "source": [
        "# Set Kaggle credentials as environment variables\n",
        "os.environ['KAGGLE_USERNAME'] = \"...\"  # your username (e.g. \"jaapjansen\")\n",
        "os.environ['KAGGLE_KEY'] = \"...\" # your API token (e.g. \"KGAT_c6344.........81e94a\")\n",
        "\n",
        "# Initialize and authenticate the Kaggle API client\n",
        "from kaggle.api.kaggle_api_extended import KaggleApi\n",
        "api = KaggleApi()\n",
        "api.authenticate()\n",
        "\n",
        "print(\"Authentication successful!\")\n",
        "\n",
        "# Define the specific ODIR-5K dataset identifier from Kaggle\n",
        "dataset_identifier = 'andrewmvd/ocular-disease-recognition-odir5k'\n",
        "\n",
        "# Download and unzip the files into a folder named 'ocular_data'\n",
        "api.dataset_download_files(dataset_identifier, path='./ocular_data', unzip=True)\n",
        "\n",
        "print(\"Download complete! Check the 'ocular_data' folder on the left sidebar.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orp-f53sxdYC"
      },
      "outputs": [],
      "source": [
        "# Read the Ocular Disease data\n",
        "data_ocu = pd.read_csv('ocular_data/full_df.csv')\n",
        "\n",
        "# Convert Kaggle-specific file paths to local Colab directory paths\n",
        "image_dir = \"ocular_data/ODIR-5K\"\n",
        "data_ocu['paths'] = data_ocu['filepath'].apply(lambda x: os.path.normpath(os.path.join(image_dir,'/'.join(x.split('/')[3:]))))\n",
        "\n",
        "data_ocu.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTUXfNL1xdYF"
      },
      "outputs": [],
      "source": [
        "# Optional: import data from Cataract dataset\n",
        "\n",
        "# Define the specific cataract dataset identifier from Kaggle\n",
        "dataset_identifier = 'jr2ngb/cataractdataset'\n",
        "\n",
        "# Download and unzip the files into a folder named 'cataract_data'\n",
        "api.dataset_download_files(dataset_identifier, path='./cataract_data', unzip=True)\n",
        "\n",
        "# Define paths for cleanup\n",
        "base_path = './cataract_data'\n",
        "inner_folder = os.path.join(base_path, 'dataset')\n",
        "temp_path = './temp_storage'\n",
        "\n",
        "# Move the folder we want to keep to a temporary spot\n",
        "shutil.move(inner_folder, temp_path)\n",
        "\n",
        "# Remove the entire original folder (deletes repo and readme)\n",
        "shutil.rmtree(base_path)\n",
        "\n",
        "# Rename the kept folder to 'cataract_data'\n",
        "os.rename(temp_path, base_path)\n",
        "\n",
        "print(\"Download complete! Check the 'cataract_data' folder on the left sidebar.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0gasxWt9jNn"
      },
      "outputs": [],
      "source": [
        "# Optional: load data from cataract dataset\n",
        "IMG_HEIGHT = 192\n",
        "IMG_WIDTH = 256\n",
        "\n",
        "# Define the root directory for the cataract dataset\n",
        "IMG_ROOT = './cataract_data/'\n",
        "\n",
        "# Initialize lists to store file paths and labels\n",
        "filepaths = []\n",
        "labels = []\n",
        "\n",
        "# Map folder names to labels\n",
        "label_map = {\n",
        "    '1_normal': '0', # Normal\n",
        "    '2_cataract': '1', # Cataract\n",
        "    '2_glaucoma': '2', # Glaucoma\n",
        "    '3_retina_disease': '3' # Retina Disease\n",
        "}\n",
        "\n",
        "# Iterate through the subdirectories to collect image paths and assign labels\n",
        "for folder_name, label_value in label_map.items():\n",
        "    folder_path = os.path.join(IMG_ROOT, folder_name)\n",
        "    for img_path in glob.glob(os.path.join(folder_path, '*')):\n",
        "        filepaths.append(img_path)\n",
        "        labels.append(label_value)\n",
        "\n",
        "# Create a DataFrame from the collected data\n",
        "cat_df = pd.DataFrame({\n",
        "    'paths': filepaths,\n",
        "    'cataract': labels\n",
        "})\n",
        "\n",
        "# Only sample normal and cataract (labels '0' and '1')\n",
        "cat_df = cat_df[(cat_df['cataract']=='0') | (cat_df['cataract']=='1')]\n",
        "cat_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zcAyoDeyxdYG"
      },
      "outputs": [],
      "source": [
        "# join datasets\n",
        "joined_cataract_data = pd.concat([cat_df, data_ocu])\n",
        "joined_cataract_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdN3ecVTxdYG"
      },
      "source": [
        "# 2. Data Exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gv8VfFicFH17"
      },
      "outputs": [],
      "source": [
        "# Visualize different Ocular Diseases\n",
        "unique_labels = data_ocu['labels'].unique()\n",
        "\n",
        "# Create a figure with one subplot for each unique label\n",
        "fig, ax = plt.subplots(1, len(unique_labels), figsize=(20, 5))  # Adjust the figure size as needed\n",
        "\n",
        "# Display one image per unique label\n",
        "for idx, label in enumerate(unique_labels):\n",
        "    # Find the first image path corresponding to the current label\n",
        "    image_row = data_ocu[data_ocu['labels'] == label].iloc[0]\n",
        "    image_path = image_row['paths']\n",
        "    image_label = image_row['labels']\n",
        "\n",
        "    # Load and display the image\n",
        "    img = plt.imread(image_path)\n",
        "    ax[idx].imshow(img)\n",
        "    ax[idx].set_title(f\"Label: {image_label}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFd0gCPdxdYG"
      },
      "outputs": [],
      "source": [
        "# Explore the data and potential null values\n",
        "data_ocu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DZB1E-RbxdYH"
      },
      "outputs": [],
      "source": [
        "# Check the distribution of labels (the different disease types)\n",
        "data_ocu['labels'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lH65vS6hxdYH"
      },
      "outputs": [],
      "source": [
        "# Check the distribution of other variables\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(data_ocu['Patient Age'], bins=30, kde=True)\n",
        "plt.title('Age Distribution of Patients')\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n",
        "\n",
        "data_ocu['Left-Diagnostic Keywords'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxOFuJg2xdYI"
      },
      "source": [
        "# 3. Create Train, Validation, and Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olDLb7LTxdYI"
      },
      "outputs": [],
      "source": [
        "# Train, Validation & Test data\n",
        "dataset = data_ocu\n",
        "y = 'labels'\n",
        "\n",
        "test_size = 0.2 # fraction of all data to be used as test data\n",
        "val_size = 0.2 # fraction of the training data (!) to be used as validation data\n",
        "\n",
        "# Do steps for cataract dataset\n",
        "train_data, test_data = train_test_split(\n",
        "    dataset,\n",
        "    stratify=dataset[y],\n",
        "    test_size=test_size,\n",
        "    random_state=1\n",
        ")\n",
        "\n",
        "# Split train_data into actual train and validation\n",
        "train_data, val_data = train_test_split(\n",
        "    train_data,\n",
        "    stratify=train_data[y],\n",
        "    test_size=val_size,\n",
        "    random_state=1\n",
        ")\n",
        "\n",
        "# Image preprocessing\n",
        "img_size = (128, 128)\n",
        "rescale = 1./255\n",
        "datagen = ImageDataGenerator(rescale=rescale) # rescale for faster convergence and preventing certain features from dominating others during training\n",
        "batch_size = 32               # number of samples that will be propagated through the network\n",
        "\n",
        "train_generator = datagen.flow_from_dataframe(\n",
        "    train_data,\n",
        "    x_col=\"paths\",\n",
        "    y_col=y,\n",
        "    shuffle = True,     # samples are randomly ordered at start of each epoch\n",
        "    target_size=img_size,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_dataframe(\n",
        "    val_data,\n",
        "    x_col=\"paths\",\n",
        "    y_col=y,\n",
        "    shuffle=False,\n",
        "    target_size=img_size,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_generator = datagen.flow_from_dataframe(\n",
        "    test_data,\n",
        "    x_col=\"paths\",\n",
        "    y_col=y,\n",
        "    shuffle = False,\n",
        "    target_size=img_size,\n",
        "    class_mode=\"categorical\",\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcWWphhAR5q2"
      },
      "outputs": [],
      "source": [
        "# Example of resizing an image\n",
        "\n",
        "# Choose the image index you want to inspect\n",
        "idx = 4\n",
        "\n",
        "# Get original image from DataFrame\n",
        "sample_path = test_data.iloc[idx]['paths']\n",
        "sample_label = test_data.iloc[idx][y]\n",
        "\n",
        "# Find which batch and which position in that batch the index belongs to\n",
        "batch_size = test_generator.batch_size\n",
        "batch_index = idx // batch_size\n",
        "sample_index_in_batch = idx % batch_size\n",
        "\n",
        "# Pull that specific batch from the generator\n",
        "images, labels = test_generator[batch_index]\n",
        "resized_image = images[sample_index_in_batch]\n",
        "\n",
        "# Plotting\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Original Image\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.imshow(plt.imread(sample_path))\n",
        "plt.title(f\"Original Image\\nLabel: {sample_label}\")\n",
        "plt.axis('off')\n",
        "\n",
        "# Resized Image (From Generator)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.imshow(resized_image)\n",
        "plt.title(f\"Resized {img_size}\\n Rescaled {rescale}\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJXRxqMqxdYI"
      },
      "source": [
        "# 4. A Basic CNN Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_LBXrQWxdYI"
      },
      "source": [
        "## 4.1 Set Hyperparameters, Create a CNN Architecture and Compile the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLPQ7GQwxdYJ"
      },
      "outputs": [],
      "source": [
        "# Set the hyperparameters\n",
        "\n",
        "## Feature Extraction\n",
        "conv_layers_one = 32          # number of filters in the first convolutional layer\n",
        "conv_layers_two = 64          # number of filters in the second convolutional layer\n",
        "conv_kernel_size = (3,3)      # size of the kernel of the convolutional layer\n",
        "conv_activation = 'relu'      # activation function of the convolutional layer\n",
        "\n",
        "## Pooling (Downsampling)\n",
        "pool_size = (2,2)             # size of pooling kernel\n",
        "\n",
        "## Classification\n",
        "fc_units = 128                # number of units in the fully-connected layer\n",
        "fc_activation = 'relu'        # type of activation function\n",
        "output_activation = 'softmax' # activation function for output layer\n",
        "\n",
        "## Training Settings\n",
        "loss_function = 'categorical_crossentropy'  # loss function\n",
        "optimizer = 'Adam'                          # optimization technique\n",
        "epochs = 1                                  # number of complete passes through the training dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cezoGUSxdYJ"
      },
      "outputs": [],
      "source": [
        "# Create the CNN architecture\n",
        "\n",
        "# Set random seed\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "# Initialize model\n",
        "cnn_model = keras.Sequential()\n",
        "\n",
        "# Input Layer\n",
        "cnn_model.add(layers.Input(shape=(img_size[0], img_size[1], 3)))\n",
        "\n",
        "# Add a first 2D Convolutional Layer: might look for simple things like edges or lines\n",
        "cnn_model.add(layers.Conv2D(conv_layers_one, kernel_size=conv_kernel_size, activation=conv_activation))\n",
        "\n",
        "# Add a 2D Max Pooling layer: downsampling step\n",
        "cnn_model.add(layers.MaxPooling2D(pool_size=pool_size))\n",
        "\n",
        "# Add a second 2D Convolutional Layer: combines those edges from first convolutional layer to find more complex shapes (like the curve of an eye or the texture of a cataract)\n",
        "cnn_model.add(layers.Conv2D(conv_layers_two, kernel_size=conv_kernel_size, activation=conv_activation))\n",
        "\n",
        "# Add a 2D Max Pooling layer: downsampling step\n",
        "cnn_model.add(layers.MaxPooling2D(pool_size=pool_size))\n",
        "\n",
        "# Flatten the results to an array (CNNs see images as 3D cubes. To classify them, we have to \"unroll\" that cube into one long line of numbers.)\n",
        "cnn_model.add(layers.Flatten())\n",
        "\n",
        "# Add a Fully-Connected Layer: the \"reasoning\" layer of your model\n",
        "cnn_model.add(layers.Dense(units=fc_units, activation=fc_activation))\n",
        "\n",
        "# Add an output layer with softmax transformation\n",
        "cnn_model.add(layers.Dense(units=len(unique_labels), activation=output_activation))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oT2mqHFyxdYJ"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "cnn_model.compile(loss=loss_function, optimizer = optimizer, metrics= ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YzLCi8v8jY4s"
      },
      "outputs": [],
      "source": [
        "# Display model structure\n",
        "cnn_model.summary()\n",
        "\n",
        "plot_model(\n",
        "    cnn_model,\n",
        "    show_shapes=True,\n",
        "    show_layer_activations=True,\n",
        "    show_layer_names=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CexsU-uxdYJ"
      },
      "source": [
        "## 4.2 Train the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KGqinXAwxdYJ"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "\n",
        "# Initialize the running time\n",
        "cnn_model_start_time = time.time()\n",
        "\n",
        "# Fit the model (split the data into a train and validation set to evaluate the model's performance during training)\n",
        "cnn_history = cnn_model.fit(\n",
        "    train_generator,\n",
        "    validation_data = val_generator,\n",
        "    epochs=epochs,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Calculate the running time\n",
        "cnn_model_end_time = time.time()\n",
        "cnn_model_running_time = cnn_model_end_time - cnn_model_start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6shDQ34PxdYK"
      },
      "source": [
        "## 4.3 Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-dsHIZfxdYK"
      },
      "outputs": [],
      "source": [
        "# Set colors for confusion matrix and accuracy plots to improve aesthetics and interpretability\n",
        "colors_dark = [\"#1F1F1F\", \"#313131\", '#636363', '#AEAEAE', '#DADADA']\n",
        "colors_red = [\"#331313\", \"#582626\", '#9E1717', '#D35151', '#E9B4B4']\n",
        "colors_green = ['#01411C','#4B6F44','#4F7942','#74C365','#D0F0C0']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fDmfynwqxdYK"
      },
      "outputs": [],
      "source": [
        "# Plot train and validation accuracy and loss over epochs\n",
        "filterwarnings('ignore')\n",
        "\n",
        "epochs_lijst = [i for i in range(epochs)]\n",
        "fig, ax = plt.subplots(1,2,figsize=(14,7))\n",
        "train_acc = cnn_history.history['accuracy']\n",
        "train_loss = cnn_history.history['loss']\n",
        "val_acc = cnn_history.history['val_accuracy']\n",
        "val_loss = cnn_history.history['val_loss']\n",
        "\n",
        "fig.text(s='Epochs vs. Training and Validation Accuracy/Loss',size=18,fontweight='bold',\n",
        "             fontname='monospace',color=colors_dark[1],y=1,x=0.28,alpha=0.8)\n",
        "\n",
        "sns.despine()\n",
        "ax[0].plot(epochs_lijst, train_acc, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n",
        "           label = 'Training Accuracy')\n",
        "ax[0].plot(epochs_lijst, val_acc, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n",
        "           label = 'Validation Accuracy')\n",
        "ax[0].legend(frameon=False)\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Accuracy')\n",
        "\n",
        "sns.despine()\n",
        "ax[1].plot(epochs_lijst, train_loss, marker='o',markerfacecolor=colors_green[2],color=colors_green[3],\n",
        "           label ='Training Loss')\n",
        "ax[1].plot(epochs_lijst, val_loss, marker='o',markerfacecolor=colors_red[2],color=colors_red[3],\n",
        "           label = 'Validation Loss')\n",
        "ax[1].legend(frameon=False)\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Training & Validation Loss')\n",
        "\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGkoUiDjlSCD"
      },
      "outputs": [],
      "source": [
        "# Predict with the model\n",
        "pred_probs = cnn_model.predict(test_generator) # Prediction on the test data\n",
        "pred_classes = np.argmax(pred_probs, axis=1)   # Select the class with the highest predicted probability as prediction outcome\n",
        "true_classes = test_generator.classes          # Select the true classes of the test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "teHS264QxdYL"
      },
      "outputs": [],
      "source": [
        "acc = accuracy_score(true_classes, pred_classes) # ratio of correct predictions (true positives + true negatives) to all predictions, indicating overall model correctness\n",
        "print(\"Test accuracy:\", acc)\n",
        "\n",
        "cm = confusion_matrix(true_classes, pred_classes) # each cell [i, j] = number of times class i was predicted as class j\n",
        "print(\"Confusion Matrix:\\n\", cm)\n",
        "\n",
        "report = classification_report(true_classes, pred_classes, target_names=list(test_generator.class_indices.keys()))\n",
        "print(\"Classification Report:\\n\", report)\n",
        "\n",
        "# TP = True Positives\n",
        "# FP = False Positives\n",
        "# FN = False Negatives\n",
        "\n",
        "# Precision = TP / (TP + FP): When the model predicts a class, how often is it correct?\n",
        "# Recall = TP / (TP + FN): Of all actual samples of a class, how many did the model find?\n",
        "# f1-score = 2 × (Precision × Recall) / (Precision + Recall): How good is the balance between precision and recall?\n",
        "# support: How many true samples of each class exist in the test set?\n",
        "\n",
        "# Macro avg:: simple average of the metric across classes. Every class counts equally, no matter how many samples it has.\n",
        "# Weighted avg: average weighted by the number of true samples per class (support)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQpSc48RRPTv"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "umcg-48-hour-case",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}